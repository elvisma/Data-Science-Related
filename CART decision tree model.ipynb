{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树：CART (Classification And Regression Tree) Based on GINI系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经济学的基尼系数：衡量国家收入差距 (>0.4 : 贫富差距悬殊，0.2-0.4 分配合理）\n",
    "### CART 里的基尼系数： gini越小， 样本差异性越小，纯度越高，分类越准确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://static001.geekbang.org/resource/image/f9/89/f9bb4cce5b895499cabc714eb372b089.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p(Ck|t) 表示节点t属于类别Ck的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化基尼系数：每个子节点的基尼系数乘以该节点占整体父亲节点D中的比例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://static001.geekbang.org/resource/image/10/1e/107fed838cb75df62eb149499db20c1e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code from CART classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 和分类树不同利用gini系数来测量不纯度不同，回归树利用样本的离散程度来评价“不纯度”，比如方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://static001.geekbang.org/resource/image/04/c1/045fd5afb7b53f17a8accd6f337f63c1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节点的划分标准，对应目标函数的最优化标准， 即最小二成偏差（LSD）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code from CART regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART 决策树的剪枝 （CCP:   Cost Complexity prune）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://static001.geekbang.org/resource/image/6b/95/6b9735123d45e58f0b0afc7c3f68cd95.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节点的表面误差率增益值，作为剪枝前后误差的定义\n",
    "### Tt代表以t为根节点的子树，C(Tt）表示节点t的子树没被剪掉时，子树Tt的误差，C(t)表示节点t子树被剪掉后的节点t的误差。\n",
    "### |Tt|代表子树Tt的叶子数， 剪枝后， T的叶子数减少1， |Tt|-1。\n",
    "### 我们希望剪枝前后误差最小，需要寻找的就是最小alpha值对应的节点，把它剪掉。生成第一个子树，然后重复，继续剪枝，知道最后只剩下根节点，即最后一个子树。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
